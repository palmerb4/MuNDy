      
All of Mundy

The following layout displayes the class/registry structure for Mundy. In this layout, we have a more palatable naming system than using long names such as
SolveLCPTechniqueBBPGDKernelDiffDots or my favorite ResolveConstraintsTechniqueNonSmoothLCPComputeConstraintViolationCollisionKernel.  
        
Because techniques and kernels are accessed via their strings and the registry, the most important thing is that our layout reflect the registry. Users will never need to write 
mundy::methods::resolve_constraints::techniques::non_smooth_lcp::compute_constraint_violation::kernels::Sphere. This will naturally arise in their parameter list when specifying
the kernel for compute_constraint_violation. 

Note, we strategically choose to not put classes like ComputeAABB in the compute_aabb namespace. At first glance this is nonuntuitive, but it is imprtitive to our code's flexibilty. 
Take, for example, time_integration::techniques::NodeEuler. This class does not currently have any techniques or required kernels, so there is no need to place it within a
time_integration::techniques::node_euler namespace. But, down the line, we may ellect to add techniques to NodeEuler, thereby necessitating the creation of a node_euler namespace. 
Hence, this design avoids needless nacespacing while still allowing extensibility. It also lets us add new techniques without forcing users to change their code. All we have to do 
is add a techniques switch to the parameters list and set the default technique to the old method.

I do have a grievance. If I (a user) want to replace NonSmoothLCP with my own method, but want to retain some of its kernels, what should be done? Copying the kernels is bad practice. 
Mundy's design needs to be flexible enough to avoid copying. Maybe registration shouldn't be done via inheritance. It gets worse; kernels are hidden in a namespace specific to 
the class they are registered to. If I wanted to swap out NonSmoothLCP, I would have to use its registry in my class. That's not unreasonable.






Things that are missing,
 - What if a constraint has multiple Lagrange multipliers like friction? The current design is sufficiently abstract to support this functionality. (Not any more)
 - Periodicity
 - How to make reading and writing the mesh easier? 
   - Need a function that takes in an stk::io::StkMeshIoBroker and adds the fields to it. Can a parameter list be provided to specify which fields (if any) to output? 
 - How to make partitioning more visible to the user?
	 - Need a function for computing/populating the parallel rank field. 
 - How to make initializing particles/constraints easier? 
	 - Need a helper function for asigning a random initial orientation and initial position. Random position should be within some bounds.
 - Desperately need to store a multibody type attribute. Users shouldnt have to specify the entire set of kernels for a sphere part. They should be able to declare the part as a sphere 
   and then list the methods that it will use. Those methods should then deduce the correct kernel based on the multibody type. 
    - Maybe add a multibody type attribute?
    - Type attributes allow for something to be both a particle and a constraint.
    - A type attribute would help us with pairwise kernel deduction. How else is ComputeConstraintForcing supposed to assign the part requirements to the given parts?
    - How can users add their own attributes? We could make a MultibodyTypeFactory and registry; the registry takes in a string and the factory maps that sting to an integer (and vice versa).
    - With that technique, how should kernels state which multibody type they are made for? Also, how do we differentiate general kernels from multibody kernels?
    - For now, I think we can keep using the current setup by introducing a pair of identifiers for each MetaTwoWayKernel. These will identify the source and target name. The input params
      for ComputeConstraintForcing will specify two sets of parts: the source parts and the target parts. Within the parsms file the source parts will have the source identifier for the TwoWay 
      kernel as a sublist. Within that sublist, the user will provide the source params. The same is true for the target identider, the target part, and the target params.
    - We will loop over the source part and check if the connected entity is in the target part, if so, we will run the source-target pairwise kernel.


I really really dislike our current constraint setup. Using a quad as a constraint and needing to have extra nodes just so we can perform connections is hidious 
and fails to have proper ghosting/sharing. Instead, the most promising alternative is to assign a single constraint-rank entity per particle to hold all of the dynamically attached nodes.
For example,
CONSTRAINT RANK:                        CONSTRAINT1
                                       /     |     \
   ELEMENT RANK:        SPRING1       /   SPHERE1   \       SPRING2
                       /       \     /       |       \     /       \
      NODE RANK:  NODE1         NODE2      NODE3      NODE4         NODE5
Rules (that will one day be hard-coded into a single data structure):
  1. Particles are abstract movers. They may or may not have mass, volume, acceleration, or inertia and somehow move when acted upon by forces. They are the only entities that get 
     constraint-rank family trees. They may be standard shapes like spheres, ellipsoids, quads, cubes, hexes, tets and can be chained together to form complex shapes; although, 
     chaining them together may require special care to resolve particle mobility and force balance. For now, we consider non-combined shapes, but with time, we will allow "globs" of 
     connected particles.
  2. Springs, hinges, and joints are immaterial, massless, inertialess constraints that apply force and are moved by other entities. They have element rank and may share nodes, edges, or 
     faces with particles or other constraints. Properly accounting for sharing of lower rank entities requires care to avoid race conditions. For example, we choose to loop over all nodes
     in the spring part, get their connected elements, and if the element is a spring, we compute and sum the force. Note, the behavior of these constraints is undefined if their nodes 
     do not connect to a particle since they will be applying force to a massless object. It's up to the user to define what happens in this circumstance.   
  3. Constraints-as-particles: Each particle will be attached to a constraint rank entity, which should be treated as an extension of the particle itself and even given the same name. The constraint
     stores the dynamic connectivity information of the particle like the nodes or edges attached to a particle's smooth surface. They may NOT connect to nodes, edges, or faces already within the 
     particle's fixed connectivity. Nodes within this family tree must be attached to the particle's surfaces, they will store a surface normal vector, velocity vector, 
     and force vector. The first element topology of the particle's dynamic family tree must be the constrained particle; everything else is a linked entity. The constraints may also 
     attach to other lower-ranked entities to guarentee proper propogation of information up and down the connectivity tree. For now, we only need to attach the nodes to communicate 
     force from the constraints to the particle and velocity from the particle to the constraints. This design works for rigid and flexible particles alike.
  5. ComputeMobility takes in the BulkData and uses it to compute the velocity of the particles/constraints. As a result, this is the class that encodes rigid body motion vs flexibility. 
     For example, rigid body motion may require ComputeMobility to sum the force from each of the linked nodes to get a single center of mass force. This force can then be used to compute 
     the center of mass velocity, and from there, the velocity of each linked node. Alternatively, a flexible immersed boundary would take in the force at each linked node, interpolate
     onto the nearby grid, solve some PDE for velocity, then integrate back to the nodes. Or, for flexible fibers, one could interpolate the linked node forces into a set of collocation 
     points, solve for the velocity of the collocation points, then interpolate the velocity back to the nodes. 


mundy::
  meta::
    FieldRequirements
    FieldRequirementsBase
    FieldRequirementsFactory
    FieldRequirementsRegistry
    MeshBuilder
    MetaKernel
    MetaKernelFactory
    MetaKernelRegistry
    MetaTwoWayKernel
    MetaTwoWayKernelFactory
    MetaTwoWayKernelRegistry
    MetaMethod
    MetaMethodFactory
    MetaMethodRegistry
    PartRequirements      
  methods:: 
    ComputeAABB
    compute_aabb::
      kernels::
        Sphere
        Spherocylinder
        SuperEllipsoid
        Polytope
        Collision
        Spring
        TorsiionalSpring
        Joint
        Hinge
    ComputeOBB
    compute_obb::
      kernels::
        Sphere
        Spherocylinder
        SuperEllipsoid
        Polytope
        Collision
        Spring
        TorsiionalSpring
        Joint
        Hinge
    ComputeBoundingRadius
    compute_bounding_radius::
      kernels::
        Sphere
        Spherocylinder
        SuperEllipsoid
        Polytope
        Collision
        Spring
        TorsiionalSpring
        Joint
        Hinge
    SolveLCP
    solve_lcp::
      techniques::
        APGDTechnique
        BBPGDTechnique
        bbpgd::
            ComputeDiffDotsKernel
            ComputeGradientStepKernel
    // neighbor methods
    DetectNeighbors
      kernels::
        SphereSphere
        SphereSpherecylinder
        SphereEllipsoid
        SpherePolytope
        SpherecylinderSpherecylinder
        SpherecylinderEllipsoid
        SpherecylinderPolytope
        SuperEllipsoidSuperEllipsoid
        SuperEllipsoidPolytope
        PolytopePolytope
    detect_neighbors::
      techniques::
        AABB
        BoundingSphere
    GhostNeighbors
    RefineNeighbors
    refine_neighbors::
      techniques::
        OBB
    // constraint methods  
    GenerateCollisionConstraints
    generate_collision_constraints::
      kernels::
        Spherocylinder
        SuperEllipsoid
        Polytope
    ResolveConstraints
    resolve_constraints::
      techniques::
        SmoothPotential          
        SmoothPenalty
        NonSmoothLCP
        non_smooth_lcp::
          ComputeConstraintViolation
          compute_constraint_violation::  
            kernels::
              Collision
              Spring
              TorsiionalSpring
              Joint
              Hinge
          ComputeConstraintForcing (D F)
          compute_constraint_forcing::
            kernels::
              Spring
              TorsiionalSpring
              Joint
              Hinge
          ComputeConstraintProjection
          compute_constraint_projection::
            techniques::
              DaiFletcher2005
              dai_fletcher::
                kernels::
                  Collision
                  Spring
                  TorsiionalSpring
                  Joint
                  Hinge
          ComputeConstraintViolationLinearizedRateOfChange (dt D^T U)
          compute_constraint_violation_linearized_rate_of_change::
              kernels::
                Collision
                Spring
                TorsiionalSpring
                Joint
                Hinge
          ComputeConstraintJacobian (dt D^T M D)
          ComputeConstraintResidual
        NonSmoothReLCP
    // motion methods
    ComputeTimeIntegration
    compute_time_integration::
      techniques::
        NodeEuler
        NodeAdamsBatchford          
    ComputeMobility
    compute_mobility::
      techniques::
        NodeEuler






Where does Mundy stand?
- Need  

Lets see the core data structures and denote them as complete. 
If incomplete, we denote their priority.
mundy::
  meta::
    (D) FieldRequirements
    (D) FieldRequirementsBase
    (D) FieldRequirementsFactory
    (D) FieldRequirementsRegistry
    (D) MeshBuilder
    (D) MetaKernel
    (D) MetaKernelFactory
    (D) MetaKernelRegistry
    (D) MetaTwoWayKernel
    (D) MetaTwoWayKernelFactory
    (D) MetaTwoWayKernelRegistry
    (D) MetaMethod
    (D) MetaMethodFactory
    (D) MetaMethodRegistry
    (D) PartRequirements      
  methods:: 
    (D) ComputeAABB
    compute_aabb::
      kernels::
        (D) Sphere
        Spherocylinder
        SuperEllipsoid
        Polytope
        Collision
        Spring
        TorsiionalSpring
        Joint
        Hinge
    (D) ComputeOBB
    compute_obb::
      kernels::
        (D) Sphere
        Spherocylinder
        SuperEllipsoid
        Polytope
        Collision
        Spring
        TorsiionalSpring
        Joint
        Hinge
    (D) ComputeBoundingRadius
    compute_bounding_radius::
      kernels::
        (D) Sphere
        Spherocylinder
        SuperEllipsoid
        Polytope
        Collision
        Spring
        TorsiionalSpring
        Joint
        Hinge
    (HIGH) SolveLCP
    solve_lcp::
      techniques::
        APGDTechnique
        (HIGH) BBPGDTechnique
        bbpgd::
            (HIGH) ComputeDiffDotsKernel
            (HIGH) ComputeGradientStepKernel
    // neighbor methods
    (HIGH) DetectNeighbors
    detect_neighbors::
      techniques::
        (HIGH) AABB
        BoundingSphere
    (HIGH) GhostNeighbors
    RefineNeighbors
    refine_neighbors::
      techniques::
        OBB
    // constraint methods  
    (HIGH) GenerateCollisionConstraints
    generate_collision_constraints::
      kernels::
        (HIGH) SphereSphere
        SphereSpherecylinder
        SphereEllipsoid
        SpherePolytope
        SpherecylinderSpherecylinder
        SpherecylinderEllipsoid
        SpherecylinderPolytope
        SuperEllipsoidSuperEllipsoid
        SuperEllipsoidPolytope
        PolytopePolytope
    (HIGH) ResolveConstraints
    resolve_constraints::
      techniques::
        SmoothPotential          
        SmoothPenalty
        (HIGH) NonSmoothLCP
        non_smooth_lcp::
          (HIGH) ComputeConstraintViolation (Constraints update their violation field)
          compute_constraint_violation::  
            kernels::
              (HIGH) Collision
              Spring
              TorsiionalSpring
              Joint
              Hinge
          (HIGH) ComputeConstraintForcing (Constraints apply force to their connected entities)
          compute_constraint_forcing::
            kernels::
              (HIGH) CollisionSphere
              CollisionSpherocylinder
              CollisionEllipsoid
              CollisionPolytope
              SpingSphere
              SpringSpherocylidner
              SpringEllipsoid
              SpringPolytope
              TorsionalSpringSphere
              TorsionalSpringSpherocylinder
              TorsionalSpring
          (HIGH) ComputeConstraintProjection (Projection of constraint force onto the feasible set)
          compute_constraint_projection::
            techniques::
              (HIGH) DaiFletcher2005
              dai_fletcher::
                kernels::
                  (HIGH) Collision
                  Spring
                  TorsiionalSpring
                  Joint
                  Hinge
          (HIGH) ComputeConstraintViolationLinearizedRateOfChange (dt D^T U)
          compute_constraint_violation_linearized_rate_of_change::
              kernels::
                (HIGH) Collision
                Spring
                TorsiionalSpring
                Joint
                Hinge
          (HIGH) ComputeConstraintJacobian (dt D^T M D)
          (HIGH) ComputeConstraintResidual
        NonSmoothReLCP
    // motion methods
    (HIGH) ComputeTimeIntegration
    compute_time_integration::
      techniques::
        (HIGH) NodeEuler
        NodeAdamsBatchford  
        node_euler::
          kernels::
            (D) Sphere
            Spherocylinder
            SuperEllipsoid
            Polytope
            Collision
            Spring
            TorsiionalSpring
            Joint
            Hinge      
    (D) ComputeMobility
    compute_mobility::
      techniques::
        RigidBodyMotion
        rigid_body_motion::
          MapRigidBodyForceToRigidBodyVelocity
          MapRigidBodyVelocityToSurfaceVelocity
          MapSurfaceForceToRigidBodyForce
          map_rigid_body_force_to_rigid_body_velocity::
            techniques::
              (D) LocalDrag
              local_drag::
                kernels::
                  (D) Sphere
                  Spherocylinder
                  SuperEllipsoid
                  Polytope
          map_rigid_body_velocity_to_surface_velocity::
            kernels::
              (D) Sphere
              Spherocylinder
              SuperEllipsoid
              Polytope
          map_surface_force_to_rigid_body_force::
            kernels::
              (D) Sphere
              Spherocylinder
              SuperEllipsoid
              Polytope

Do the existing methods work correctly with ghosting/sharing?
All the existing methods loop over locally owned parts and do not perform communication. This is fine for 
- compute_aabb
- compute_bounding_radius
- compute_obb
- detect_neighbors (since it only needs the local AABB or OBB field)
- compute_constraint_projection
- compute_constraint_violation (needs aura communication)
- refine_neighbors (needs aura communication)
- generate_collision_constraints (needs aura communication)
- compute_constraint_forcing (needs aura communication)
but not for compute_mobility since we write out velocity to ghosted or shared nodes. We need an addition step where we communicate these changes.
This communication occurs after the kernels, causing some issues with our current requirements setup. This issue is caused by something else that 
has troubled me. Kernels are the ones that ask for specific fields meaning that the AABB field name may differ from kernel to kernel. It should 
really be ComputeAABB that specifies the modified fields and the kernels that modify them. Kernels then specify kernel-specific fields. If ComputeMobility
stored velocity and not just the kernels, then we could perform the communication with ease. The same goes for methods that should zero out fields. 

We can make compute_time_integration work with proper sharing/ghosting so long as we loop over all nodes and update their position. Currently, this won't
work because of updating the element orientation, but there is honestly no reason to store orientation just to have oriented spheres. If the user wants 
an oriented sphere method, they can easily make one. As a result, NodeEuler should only update the position of all nodes in the given parts. It couldn't care
less about linkers, particles, or spheres and ellipsoids. This means we can loop over local nodes and be perfectly fine. 

Order I will implement things
3. (Done) compute_mobility::techniques::LocalDrag
  - Given the BulkData, use the surface and body forces on the particles to compute their center of mass force, 
  - Use local drag to map this force to center of mass velocity. 
  - Use rigid body motion to map this velocity to surface velocity.
  (Done) 1. compute_mobility::MapSurfaceForceToRigidBodyForce
    - Sum the surface forces to get the total force at a known location in the rigid body (not necessarily the center of mass). 
  (Done) 2. compute_mobility::MapRigidBodyVelocityToSurfaceVelocity
    - Use rigid body motion about a known point to compute the velocity at all surface points.
4. (Done) ComputeMobility
  - Parses the given parameter list and calls the given technique.
5. (Done) compute_time_integration::techniques::NodeEuler
  - Given the BulkData, loops over the fixed and dynamic nodes of each particle and updates their position based on a first-order Euler step. 
  - Because this process is first-order, we naturally satisfy rigid body motion. If this process were higher order, then the surface points have the potential to leave the surface.
    I would like to restrict rigid body motion to ComputeMobility so this is a problem for another day. 
6. (Done) ComputeTimeIntegration
  - Parses the given parameter list and calls the given technique.
7. (Done) resolve_constraints::techniques::non_smooth_lcp::compute_constraint_forcing::kernels::Collision
  - Takes in a node within the collision part, fetches the attached elements, if they are in the collision part, computes and sums the constraint force
  - Computes and sums the constraint force from 
8. (Done) resolve_constraints::techniques::non_smooth_lcp::compute_constraint_projection::kernels::Collision
9. (Done) resolve_constraints::techniques::non_smooth_lcp::compute_constraint_violation::kernels::Collision
10. (Done) resolve_constraints::techniques::non_smooth_lcp::ComputeConstraintForcing
  - Zeros the constraint force on all constraint nodes.
  - Loops over the given constraint parts and runs the i'th kernel for each NODE in the i'th part.
  - The elements of the constraints need to have some up-to-date information for this to work. For example, springs and collisions need the separation distance.
11. (Done) resolve_constraints::techniques::non_smooth_lcp::ComputeConstraintProjection
  - Loops over the given constraint parts and runs the i'th kernel for each ELEMENT in the i'th part.
12. (Done) resolve_constraints::techniques::non_smooth_lcp::ComputeConstraintViolation
  - Loops over the given constraint parts and runs the i'th kernel for each ELEMENT in the i'th part.
13. (Done) resolve_constraints::techniques::non_smooth_lcp::ComputeConstraintResidual
  - Loops over the given constraint parts and runs the i'th kernel for each ELEMENT in the i'th part.
14. (Done) resolve_constraints::techniques::NonSmoothLCP
  - Perform the BBPGD non-smooth LCP solve, calling the correct sub-methods when necessary.
15. (Done) ResolveConstraints
  - Given BulkData with up-to-date constraints, parse the input params and call the desired technique.
16. generate_collision_constraints::kernels::SphereSphere
  - Given two sphere elements, generate the collision constraint between them. Make sure both elements are spheres! If they aren't just continue on. 
17. GenerateCollisionConstraints
  - Given the BulkData with an up-to-date neighbor list mesh attribute, generate collision constraints between any two neighbors that don't already have a collision constraint.
  - Choose the appropriate pairwise kernel based on part membership.
18. UpdateConstraints
  - Given the BulkData, update the constraints as though they had just been generated. 




There are some BIG changes that need to occur. Those are
0. Passing fields/parameters to sub-methods/sub-kernels. (Who should be the one to zero out the fields?)
1. The parameters for all methods and kernels need broken into fixed and mutable parameters.
2. All details_static_get_valid_params need updated to return the kernel/submethod params. 
   It should look a lot like details_static_get_mesh_requirements
3. Need a way to have default parameters for different multiboidy types without the user needing to specify every single kernel. 
   One promising method is to have a parameter like, use_present_default_parameters: SPHERE. 


Kernels allow methods to perform different actions upon one part vs another. One of the core issues is that users currently specify ALL kernels for EVERY part. Not only that, 
there is currently no way to fetch the default/valid parameters. What we want is a set of default parameters such that the users can identify their part as a sphere and it 
automatically use the sphere kernels. A multibody type identifier would take care of this. For example, each method/sub-method would parse its registered multibody types, 
get the requirements for each, and then output those. Now, if we do this right, then there should be a method for adding a sub-multibody type, such as a colored sphere, that
picks up some of the sphere's defaults but is able to overwrite others. Why does it need to pick up the defaults? We need a checker that can tell if a multibody type is a 
sub-type. That way, we only need to specify kernels for colored spheres in a few isolated locations. Can this be achieved using part inheritance? For example, we always add
a sphere part and if you are a sub-part of the sphere part then you automatically pick up the sphere kernels. OHHHH, we need a way to specify multibody types as sub-multibody 
types such that we can generate the set of parts for those multibody types and have them be subparts of their parent type. 

To be honest, the current design almost achieves this. Colored spheres are spheres, so they can be used with the sphere kernel so long as you list their kernels as being 
sphere kernels. PartRequirements allowed subparting. The ColoredSphere kernels could explicitly identify the ColoredSpheres are subparts of Spheres. THE PART REQUIREMENTS
CAN ENCODE THE MULTIBODY TYPE AND WE CAN USE THEM TO CREATE THE MULTIBODY INHERITANCE TREE! Ok, this is a big big change and I'm happy we figured it out. In the meantime, 
I'll turn off parameter validation and will expect users to specify all parameters exactly. Methods must be given field names and cannot set them explicitly because the 
same method may need ran twice: once with one set of field names then again with another set. This creates an issue for our design since we can't assign fields to our
inheritance tree if the fields don'e have names! Nevermind, the part requirements take in the fixed parameters, so we are able to access the field names. 

Not every kernel has a multibody type associated with it. I could have kernels for acting on a grid that perform different actions based on topology. Kernels are meant to 
perform a different action on a specific group based on some identifying attribute about that group. If we better abstract our kernels to reduce duplicative code, then 
we can introduce different kernels based on the thing that sets them apart. That's the class identifier. What you're getting at is that the class identifier type should be 
templated. Multibody kernels are just those that are identified by a mundy::multibody::multibody_t, topology kernels are those that are identified by an
stk::topology::topology_t, general kernels are those that are identified by a string name. 

For example, you could have a MultibodyKernel acts on a specific multibody type or you could have a topology ke





I don't think that we should force all multibody types to have the same aabb field name or same node force name. Now, it's better for performance if we do, but it's an
unnecessary restriction. The only reason we wanted to make the change, where methods fetch and then pass down the chain fields like aabb, was to allow certain methods
to zero-out force fields. Instead, why don't we loop over each of the kernels, fetch their force field and zero it out? That would require us to force all sub-kernels
to have a parameter with the aabb_field_name. I'm ok with that.

sphere_part, ellipsoid_part, collision_part, etc. 
     |
colored_sphere_part

The kernels and methods all specify 


What are the required parameters for every method? 


What we currently do:
ComputeAABB
  input_parts:
    count: 2
    input_part_0:
      name:
      kernels:
        name: sphere
        buffer_distance:
        aabb_field_name:
        radius_field_name:
    input_part_1:
      name:
      kernels:
        name: ellipsoid
        buffer_distance:
        aabb_field_name:
        axis_length_field_name:

What we should do with multibody types:
ComputeAABB
  kernels:
    count: 2
    kernel_0: 
      multibody_type: sphere
      buffer_distance:
      aabb_field_name:
      radius_field_name:
    kernel_1: 
      multibody_type: ellipsoid
      axis_length_field_name:

What we expect the user to provide:
ComputeAABB
  kernels:
    count: 2
    kernel_0: 
      multibody_type: sphere
      buffer_distance:
      aabb_field_name:
      radius_field_name:
    kernel_1: 
      multibody_type: ellipsoid
      buffer_distance:
      aabb_field_name:
      axis_length_field_name:



What should mundy multibody look like? 
Well, if we store a multibody base type (just like stk::topology), then we can have sub-multibody types. 

Big issue. mundy::multibody needs to be extensible. I state this because that is the only way for users to swap out multibody kernels for their own. 
This way, colored spheres can be a multibody type, allowing users to make their own multibody kernel specializations for them. Otherwise, colored spheres
would only ever act like spheres. We shouldn't use enums directly. I would rather have a static map from string to int. The int is our multibody type.
From there, can we map from mundy::multibody::multibody_t to mundy::multibody in a way that users can extend? This way we can add a method for automatically
mapping mundy::multibody to an stk::topology.

static const mundy::multibody::multibody_t class_identifier_ = mundy::multibody::Sphere::get_id();

There's no way to go the other direction without using pointers. You'd have to map to Multibody directly, which would discard all information about the sphere. 
Because these classes are entirely static, the factory can store all of their methods in jump tables. Then we either use the id or the string to call the correct method. 

This means that Multibody can use CRTP to force each derived class to implement a certain static interface, the factory will store this interface. 
If we name the factory multibody, then we can do things like

unsigned id = mundy::MultibodyFactory::get_id("SPHERE");
std::string name = mundy::MultibodyFactory::get_name(id);
mundy::MultibodyFactory::get_topology(multibody_name);
mundy::MultibodyFactory::get_topology(multibody_id);
mundy::MultibodyFactory::is_valid(multibody_id);
mundy::MultibodyFactory::is_valid(multibody_name);
mundy::MultibodyFactory::has_parent(multibody_id);
mundy::MultibodyFactory::has_parent(multibody_name);
mundy::MultibodyFactory::get_parent(multibody_id);
mundy::MultibodyFactory::get_parent(multibody_name);

mundy::
  Multibody
  MultibodyRegistry
  MultibodyFactory
  multibody_types::
    Sphere
    Collision

Now, we do the same thing as MetaMethod, we use a string to register each multibody type (Sphere, Collision, Spring) and sequentially assign them an integer ID. 
The problem I have is that there's no need to output shared pointers to MultibodyBase everywhere; I want to directly interface with mundy::Multibody

I cannot force the children to implement a set static interface without using CRTP. Is that a bad thing? 
Well, I won't be able to use mundy::Multibody directly and I cannot output mundy::Sphere directly without outputting a pointer to MultibodyBase. 

class mundy::Multibody:
  public:
    using multibody_t = unsigned;

    static 

  private:
    static constexpr std::string_view name_ = "INVALID";
    static constexpr multibody_t type_ = MultibodyRegistry::get_multibody_type(name_); 
    static constexpr stk::topology topology_ = stk::topology::INVALID_TOPOLOGY;


Just like topology_data, we can use the following to convert our integer id to compile-time information like name, type, topology. 
mundy::multibody::multibody_data<mundy::multibody::multibody_t>

Unlike MetaMethod or MetaKernel, each multibody_data contains the same amount of information as all the others and they are entirely static entities. 



In the future, we should consider adding a MeshRequirements which contains the part requirements but also allows
mesh attributes.

The current TODO:
(DONE) 1. Use the multibody factory to fetch the correct kernels
2. Store the multibody type on the parts 
  (Done) 2.1. Update the PartRequirements to support part attributes and field attributes
  2.2. Replace details_static_declare_mesh_requirements with the old style
3. Update the valid parameters of every Method to reflect the changes to multibody kernels. 
  3.1. ComputeAABB.hpp somewhat reflects this change but not ComputeAABB.cpp.
4. Change the part requirements to use the provided parameters. These are not MeshRequirements. 
  4.1. If a field name is not provided, use the default.
  4.2. Assign mesh fields, attributes, parts, subparts, and all fields.
4. A PartVector should be passed into the execute command rather than passing the names to the Params. We'll 
   find the intersection of that PartVector and each multibody type to choose the correct kernel. 
5. Update the constructors of each kernel and method to populate their temporaries with defaults. 
6. Store the neighbor list as a mesh attribute. 
  6.1. (Done) Instead of returning PartRequirements we should return MeshRequirements, which stores a vector of PartRequirements and any mesh attributes.
7. 


TO AVOID RACE CONDITIONS, MULTIBODY TYPES SHOULD NOT HAVE INHERITANCE. 


Using a fast id instead of a string seems tempting for choosing our kernels but the user needs to specify the kernel name in the
parameters, which means that the identifier needs to a string. 

Even more importantly, once someone registers a kernel with a certain multibody type, that kernel cannot be replaced. I'm not sure how to 
resolve this and still have kernels automatically associated with a certain multibody type. Can registration be removed?

Part/Field/Mesh requirements need a way to take in any number of requirements into their parameter_list constructor. This can't happen until I figure out Meulu's parser.